<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Of Seals, Dogs and Dolphins with Python - Blog</title><link rel=icon type=image/png href=img/favicon.ico><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="Using Approximate Nearest Neighbors to stitch images to images"><meta property="og:image" content><meta property="og:title" content="Of Seals, Dogs and Dolphins with Python"><meta property="og:description" content="Using Approximate Nearest Neighbors to stitch images to images"><meta property="og:type" content="article"><meta property="og:url" content="https://kevinkle.in/posts/2022-09-25-collage/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-10-02T07:38:07+02:00"><meta property="article:modified_time" content="2022-10-02T07:38:07+02:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Of Seals, Dogs and Dolphins with Python"><meta name=twitter:description content="Using Approximate Nearest Neighbors to stitch images to images"><script src=https://kevinkle.in/js/feather.min.js></script><link href=https://kevinkle.in/css/fonts.b685ac6f654695232de7b82a9143a46f9e049c8e3af3a21d9737b01f4be211d1.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://kevinkle.in/css/main.3a1de2917438aeff713f11261cc8e65bc6d4705113bc0ef12e161e5731d820b5.css></head><body><div class=content><header><div class=main><a href=https://kevinkle.in/>Blog</a></div><nav><a href=/about>Hello</a>
<a href=/tags>Tags</a>
<a href=/projects>Projects</a>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></nav></header><main><article><div class=title><h1 class=title>Of Seals, Dogs and Dolphins with Python</h1><div class=meta>Posted on Oct 2, 2022</div></div><section class=body><p>Every now and then I have come across prints of image collages or &lsquo;mosaics&rsquo;. Often it&rsquo;s
been ads, say a Greenpeace collage of small images portraying poorly treated puppies -
that is, if you&rsquo;re able to squint your eyes real hard - making up for the overall image
of a happy dolphin, or so.</p><p>Anyhow! - I&rsquo;ve almost always found these collages to be aesthetically displeasing. At the
same time they somehow caught and kept my attention. The last time I saw one of them
I wondered how one would go about creating one of these. I figured some kind of a <a href=https://en.wikipedia.org/wiki/Nearest_neighbor_search>nearest
neighbor search</a> would come in handy.</p><p>Here we go!</p><h1 id=method>Method</h1><p>The way I went about it is conceptually very simple.</p><p>First, the reference collection of component images (e.g. 10,000 images of puppies) should
be preprocessed. On the one hand, they should be scaled down to a suitable size, e.g.
20x20 pixels. On the other hand, an <a href=https://en.wikipedia.org/wiki/Search_engine_indexing>index</a>
over these images is created. On a high level the index should help answer to the following query
fast:</p><blockquote><p>Given an actual pixel in the target image (e.g. the eye of the dolphin), which image from
the reference collection (e.g. which puppy) works best as a substitute?</p></blockquote><p>This question could be framed as that of a minimal distance, i.e.</p><blockquote><p>Between which image in the reference collection and the pixel of the target image is the
distance least?</p></blockquote><p>This, in turn, bares the question of how one might define a notion of distance. My impression
is that both the human eye as well as human perception more generally are serious business. I
have no clue whether</p><ul><li>within a <a href=https://en.wikipedia.org/wiki/Channel_(digital_image)>channel</a>, average values capture the essence</li><li>in how far channels interact with each other</li><li>the euclidean distance between pixel/patches captures the notion of similitude</li></ul><p>when it comes to visual human perception.</p><p>Nevertheless, I tried this and it seems to work okay. Slightly more formally, the distance
between a reference image \(I^{ref}\) and a target image pixel \(I_{ij}^{target}\) looks as follows:</p><p>$$ d(I^{ref}, I_{ij}^{target}) = (\sum_{c \in \{r, g, b\}} (I_{ijc}^{target} - avg(I_c^{ref}))^2)^{1/2} $$</p><p>Given this notion of a distance, an index on the reference images can be built.</p><p>Given that our queries and image representations only rely on three dimensions,
an exact nearest neighbor method, such as <a href=https://en.wikipedia.org/wiki/K-d_tree>k-d trees</a>,
certainly works just fine. I opted to use <a href=https://github.com/spotify/annoy>annoy</a>, a library
for approximate nearest neighbor retrieval.
Just like k-d trees, annoy relies on building a forest of trees splitting the input
space by hyperplanes.</p><p>Once the reference images can be efficiently queried, one must only define a way to use
the reference images to create a target image. The idea here is to create a 1-to-1
correspondence between an individual pixel in the target image and an entire reference
image. Based on aforementioned distance, we simply substitute every target image by
the most suitable reference image.</p><p>Putting it all together, the process looks as follows:</p><ol><li>Pre-processing of reference images</li></ol><pre tabindex=0><code class=language-preprocessing data-lang=preprocessing>for every image in refrence collection:
    downscale the image
    compute average value per rgb channel
    insert image into index based on average rgb channel values
</code></pre><ol start=2><li>Building of collage imitating target image</li></ol><pre tabindex=0><code>for pixel in target image:
    pick rgb values of this pixel
    find reference image in index that is closest to these rgb values
    substitute pixel by retrieved reference image
</code></pre><p>One might want to extend the approach in many ways. For instance, one might want to impose a
reference image specific budget. In other words, one might want that a specific reference is
used at most \(k\) times in the collage.</p><p>Similarly, one might want to ensure that every image from the reference collection has been
used at least once.</p><h1 id=usage>Usage</h1><p>I condensed this into a small python package and CLI utility called <code>pycollage</code>. Its code
is public on GitHub, see <a href=https://github.com/kklein/pycollage>here</a>.</p><p>One can install it via PyPI</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span>$ pip install pycollage
</span></span></code></pre></div><p>or via conda-forge</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span>$ conda install pycollage -c conda-forge
</span></span></code></pre></div><p>It comes with a fairly simple interface:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span>$ pycollage process-collection /users/Anne/image_collection
</span></span><span style=display:flex><span>$ pycollage build /users/Anne/index /users/Anne/target_image.png
</span></span></code></pre></div><p>where e.g. <code>users/Anne/image_collection</code> is a directory with many images of
puppies and e.g. <code>users/Anne/target_image.png</code> is the path of the dolphin image.</p><p>The <a href=https://github.com/kklein/pycollage#installation>readme</a> comes with more information.</p><h1 id=example>Example</h1><p>Since I&rsquo;m not Greenpeace and since I like seals slightly better than dolphins, here
is a seal with a heart-shaped nose made up of dogs:</p><p><a href=https://photos.app.goo.gl/DKbrLQo4p6QaG4Q96>https://photos.app.goo.gl/DKbrLQo4p6QaG4Q96</a></p><h1 id=update-221010>Update 22/10/10</h1><p>It seems as though it would make more sense to use the <a href=https://en.wikipedia.org/wiki/CIELAB_color_space>CIELAB space</a>, rather than rgb for retrieval.</p></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/math>math</a></li><li><a href=/tags/tech>tech</a></li></ul></nav></div></article></main><footer><div style=display:flex><a class=soc href=https://github.com/kklein title=GitHub><i data-feather=github></i></a><a class=soc href=https://twitter.com/kevkle title=Twitter><i data-feather=twitter></i></a></div><div class=footer-info>2024 Â© Kevin Klein |</div></footer><script>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-SGRSG6Y0WX","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script><script>feather.replace()</script></div></body></html>