<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Inference - Blog</title><link rel=icon type=image/png href=img/favicon.ico><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="No, the other inference!"><meta property="og:image" content><meta property="og:title" content="Inference"><meta property="og:description" content="No, the other inference!"><meta property="og:type" content="article"><meta property="og:url" content="https://kevinkle.in/posts/2022-06-06-inference/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-06-05T07:38:07+02:00"><meta property="article:modified_time" content="2022-06-05T07:38:07+02:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Inference"><meta name=twitter:description content="No, the other inference!"><script src=https://kevinkle.in/js/feather.min.js></script><link href=https://kevinkle.in/css/fonts.b685ac6f654695232de7b82a9143a46f9e049c8e3af3a21d9737b01f4be211d1.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://kevinkle.in/css/main.3a1de2917438aeff713f11261cc8e65bc6d4705113bc0ef12e161e5731d820b5.css></head><body><div class=content><header><div class=main><a href=https://kevinkle.in/>Blog</a></div><nav><a href=/about>Hello</a>
<a href=/tags>Tags</a>
<a href=/projects>Projects</a>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></nav></header><main><article><div class=title><h1 class=title>Inference</h1><div class=meta>Posted on Jun 5, 2022</div></div><section class=body><p>I had long felt a slight discomfort with the word &lsquo;inference&rsquo;. Many people seemed to use it with confidence and the expectation that it would refer to a precise notion. And while it is not uncommon for a word to have different meaning in different contexts, it took me a while to figure out what the different meaning and what the different contexts are in the example of &lsquo;inference&rsquo;. <a href=https://stackoverflow.com/questions/55852777/is-training-inference-terminology-in-deep-learning-any-different-than-train-te>Some other people seem to be a little confused as well</a>.</p><h1 id=inference-in-statistics>Inference in statistics</h1><p>Inference being a common term in statistics<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>, I looked for definitions of the term in the statistics context.</p><p>In &lsquo;All of Statistics&rsquo;, Larry Wassermann writes the following:</p><blockquote><p>Statistical inference, or &ldquo;learning&rdquo; as it is called in computer science, is the process of using data to infer the distribution that generated the data. The basic statistical inference problem is this:
We observe \(X_1, \dots, X_n \sim F\). We want to infer (or estimate or learn) \(F\) or some feature of \(F\) such as its mean.</p></blockquote><p>In a similar vein, the authors of &lsquo;Introduction to Statistical Learning with R&rsquo; elaborate further:</p><blockquote><p>[&mldr;] we wish to estimate f, but our goal is not necessarily to make predictions for \(Y\). We instead want to understand the relationship between \(X\) and \(Y\), or more specifically, to understand how \(Y\) changes as a function of \(X_1, \dots, X_n\).</p></blockquote><p>In a more applied setting, the <a href="https://www.statsmodels.org/stable/emplike.html?highlight=inference">statsmodels documentation</a> also uses the term inference in relation to estimating the parameters of a distribution.</p><h1 id=inference-in-machinedeep-learning>Inference in machine/deep learning</h1><p>In the at least adjacent, possibly overlapping field of machine learning, there seems to exist a different interpretation of the word.</p><p>Kevin Murphy writes in his recent &ldquo;Probabilistic Machine Learning: An Introduction&rdquo;:</p><blockquote><p>In the deep learning community, the term “inference” refers to what we will call “prediction”, namely computing \(p(y|x, \theta)\).</p></blockquote><p>In their <a href=https://arxiv.org/pdf/1907.01989.pdf>paper</a> on on-device inference, Lee et al. from Google implicitly contrast training and inference:</p><blockquote><p>Our work is complementary to these efforts and instead focuses on optimizing the inference engine that runs the neural network rather than the model or training</p></blockquote><p>In a similarly applied setting, <a href=https://docs.microsoft.com/en-us/azure/machine-learning/concept-onnx>Microsoft&rsquo;s Azure documentation on ONNX</a> states the following:</p><blockquote><p>Learn how using the Open Neural Network Exchange (ONNX) can help optimize the inference of your machine learning model. Inference, or model scoring, is the phase where the deployed model is used for prediction, most commonly on production data.</p></blockquote><p>This seems quite different from the above statistics interpretations. Granted, this is not to say that all members of the community agree with this meaning - merely that some do.</p><h1 id=summary>Summary</h1><p>Taking a step back we might look for a more general definition of the term inference. The <a href="https://www.oxfordlearnersdictionaries.com/definition/english/inference#:~:text=%2F%CB%88%C9%AAnf%C9%99r%C9%99ns%2F,you%20already%20know%20synonym%20deduction">Oxford Learner&rsquo;s Dictionary</a> defines inference as follows:</p><blockquote><p>something that you can find out indirectly from what you already know</p></blockquote><p>This general definition aligns with both kinds of meanings encountered in the excerpts before. What differs is what one finds outs - new data points or functions/parameters - and what one already knows - observed data or functions/parameters.</p><p>The references above paint a more general and all-encompassing picture. Yet, in an attempt to clearly contrast the terminologies, one might assume a supervised learning setup. In this setup, there is observed input data \(X_{train}\) with labels \(y_{train}\). This data is used to fit parameters \(\hat{\theta}\) or more generally a function \(\hat{f}\). The latter can then be used to predict labels of other data, \(X_test\). Given the interpretations above, the following is <em>a</em> possible landscape of terminologies:</p><table><thead><tr><th></th><th>\((X_{train}, y_{train})\)</th><th>\(\rightarrow\)</th><th>\(\hat{\theta}\) or \(\hat{f}\)</th><th>\(\rightarrow\)</th><th>\((X_{test},\hat{y}_{test})\)</th></tr></thead><tbody><tr><td>Statistics</td><td></td><td>Inference or estimation</td><td></td><td>Prediction</td><td></td></tr><tr><td>Machine/Deep learning</td><td></td><td>Training</td><td></td><td>Inference or prediction</td><td></td></tr></tbody></table><p>In conclusion, there are at least <em>some</em> people working on clearly related topics using at best inconsistent, at worst contradicting terminology. In order to facilitate knowledge transfer between fields, communities and teams it might be worth considering to use less ambiguous terminology or to least qualify the term inference, e.g. by saying &lsquo;parameter inference&rsquo; - unless the meaning is rendered crystal clear by its context, even to the uninitiated reader. Communication remains hard, but a battle worth fighting. :)</p><h1 id=whats-more>What&rsquo;s more</h1><p>Bayesian inference typically refers to using observations, \(x_i\), in order to update a prior belief<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, \(p(\theta_{i-1})\) to a posterior \(p(\theta_i | x_i) \). DeepAi provides an <a href=https://deepai.org/machine-learning-glossary-and-terms/bayesian-inference>example</a>.</p><p>Variational inference techniques attempt to find approximate solutions to numerically challenging, conventional inference problems. Stefano Ermon&rsquo;s class provides a <a href=https://ermongroup.github.io/cs228-notes/inference/variational/>short overview</a>.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>E.g. The <a href=https://en.wikipedia.org/wiki/Statistics>wikipedia article</a> on statistics uses the word inference 17 times.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Note: this is a priori not the same \(\theta\) as before.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/math>math</a></li><li><a href=/tags/tech>tech</a></li></ul></nav></div></article></main><footer><div style=display:flex><a class=soc href=https://github.com/kklein title=GitHub><i data-feather=github></i></a><a class=soc href=https://twitter.com/kevkle title=Twitter><i data-feather=twitter></i></a></div><div class=footer-info>2023 © Kevin Klein |</div></footer><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-SGRSG6Y0WX","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script><script>feather.replace()</script></div></body></html>