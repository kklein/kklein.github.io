<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>tech on Blog</title><link>https://kevinkle.in/tags/tech/</link><description>Recent content in tech on Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Â© Kevin Klein</copyright><lastBuildDate>Sun, 22 May 2022 07:38:07 +0200</lastBuildDate><atom:link href="https://kevinkle.in/tags/tech/index.xml" rel="self" type="application/rss+xml"/><item><title>Life Monitor</title><link>https://kevinkle.in/posts/2022-05-21-life_monitor/</link><pubDate>Sun, 22 May 2022 07:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2022-05-21-life_monitor/</guid><description>Motivation On the one hand, there are things we notice &amp;lsquo;automatically&amp;rsquo;, easily, without consciously paying attention to them. On the other hand, there are things that slip through the cracks unless we make a point out of monitoring them.
It might seem very natural that whether something is effortlessly &amp;lsquo;visible&amp;rsquo; is highly dependent on other properties of that very same something. It occurred to me that I have a tendency to be less receptive for observations that</description></item><item><title>Org Log</title><link>https://kevinkle.in/posts/2022-02-27-org_journal/</link><pubDate>Sun, 27 Feb 2022 09:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2022-02-27-org_journal/</guid><description>I have long been an avid enthusiast of journaling. This has mostly been for the sheer sake of journaling. In other words: once written, never to be read.
At the same time I would like to use information about my past when making decisions for the future. When simply winging this inference on empirical data, I&amp;rsquo;m always worried that some warping could have altered my recollection of these experiences (in other words: a noisy communication channel) and thereby bias my inference mechanism unjustly.</description></item><item><title>Sudoku #3: Poor Man's RL</title><link>https://kevinkle.in/posts/2022-01-09-sudoku_rl/</link><pubDate>Sun, 13 Feb 2022 08:00:07 +0200</pubDate><guid>https://kevinkle.in/posts/2022-01-09-sudoku_rl/</guid><description>Previously, I&amp;rsquo;ve outlined some ideas on how to solve Suduko puzzles. One revolved around depth-first search in trees, one around linear programming. This time I tried my luck with a more adventurous, data-driven approach: Reinforcement Learning. First things first: the approach only works well for 4x4 grids - not for the typical 9x9. Please note that the approached subsequently outlined couldn&amp;rsquo;t be further from a recommendable approach to solving Sudoku puzzles.</description></item><item><title>2021 in Running</title><link>https://kevinkle.in/posts/2021-12-27-2021_running/</link><pubDate>Mon, 27 Dec 2021 02:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2021-12-27-2021_running/</guid><description>As another year is coming to an end I&amp;rsquo;m curious: What has my running looked like this year? I did something similar in 2020 as well as in 2019.
The gist of it 2018 2019 2020 2021 distance [km] 430 962 1295 1381 avg distance [km] 6.61 9.08 10.53 11.05 #runs 65 107 123 124 #sports activities 81 135 210 231 share of running among sports activities 80.25% 79.26% 58.57% 53.</description></item><item><title>Sudoku #2: Linear Programming</title><link>https://kevinkle.in/posts/2021-03-14-sudoku_lp/</link><pubDate>Sun, 14 Mar 2021 11:00:07 +0200</pubDate><guid>https://kevinkle.in/posts/2021-03-14-sudoku_lp/</guid><description>Abstract As discussed in this previous post, a given Sudoku puzzle can be modeled in a multitude of ways. Different algorithms ought to still lead to the same solution, since a correct Sudoku puzzle comes with a unique solution. In this post we&amp;rsquo;ll rely on optimization&amp;rsquo;s poster child: Linear programming.
Idea A linear program, subsequently referred to as LP, comes with three central building blocks:
An objective function Typically many variables, each, a priori, non-integer numbers Linear constraints on the variables Since, thanks to our assumption of a well-posed puzzle we know that:</description></item><item><title>Sudoku #1: Depth-First Search</title><link>https://kevinkle.in/posts/2021-02-28-sudoku_dfs/</link><pubDate>Sun, 28 Feb 2021 19:00:07 +0200</pubDate><guid>https://kevinkle.in/posts/2021-02-28-sudoku_dfs/</guid><description>Abstract Solving a Sudoku board can be done in many ways. Let&amp;rsquo;s explore a depth-first search approach in this post.
Idea Depth-first search or DFS implies (at least) two things:
a graph, or rather, a tree a search This bares the question: What&amp;rsquo;s the tree and what are we searching for?
The tree A tree must consist of nodes and edges. We define the nodes to represent a &amp;lsquo;state&amp;rsquo; of the game.</description></item><item><title>2020 in Running</title><link>https://kevinkle.in/posts/2020-12-27-2020_running/</link><pubDate>Sun, 27 Dec 2020 00:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2020-12-27-2020_running/</guid><description>Yet another year&amp;rsquo;s almost over. Let&amp;rsquo;s have a look at my year 2020 in running, just as I did in 2019.
Yearly comparison 2018 2019 2020 distance [km] 430 962 1295 avg distance [km] 6.61 9.08 10.53 number of runs 65 107 123 share of running among sport activities 80.25% 79.26% 58.57% I picked up going to the gym in late 2019 and started cycling every now and then in 2020, hence the lower share of running.</description></item><item><title>Markov Random Field Image Denoising</title><link>https://kevinkle.in/posts/2020-03-27-mrf/</link><pubDate>Sun, 26 Apr 2020 09:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2020-03-27-mrf/</guid><description>This post describes the application of a Probabilistic Graphical Model for simple image denoising, as suggested in Bishop&amp;rsquo;s chapter 8.3.8. I will attempt to introduce some notions for general context without derivations. Googling will lead to plenty of useful resources. On an introductory level, I enjoyed Daphne Koller&amp;rsquo;s class.
Context: Probabilistic Graphical Models Probabilistic Graphical Models are tools to model and express conditional independencies among a set of random variables.</description></item><item><title>Playlist Chatbot</title><link>https://kevinkle.in/posts/2020-03-27-playlist-chat-bot/</link><pubDate>Fri, 27 Mar 2020 16:00:00 +0200</pubDate><guid>https://kevinkle.in/posts/2020-03-27-playlist-chat-bot/</guid><description>Countless times have I found myself in the situation of receiving a telegram message of following kind:
On the one hand I find this immensely exciting:
A friend takes time to share something with me. I take pleasure in exploring music per se. Both conjuncted, there is a possibility to bond over music. Hence there is a great amount of potential!
Yet, on the other hand, it&amp;rsquo;s a bit of a mess.</description></item><item><title>Update: Time Is Money</title><link>https://kevinkle.in/posts/2020-03-26-tim_update/</link><pubDate>Thu, 26 Mar 2020 16:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2020-03-26-tim_update/</guid><description>A while back, I wrote about Time Is Money.
Back then I ran into several technical problems with modern browsers&amp;rsquo; idle api.
Circumventing these with a somewhat brute approach made it possible to get the extension to run more smoothly. Besides still being able to build it from source, it is now available in the chrome extension store.
Current behaviour In the extension options, a user can specify an hourly wage as well as a set of undesirable websites.</description></item><item><title>Log, Right?</title><link>https://kevinkle.in/posts/2020-01-16-log/</link><pubDate>Thu, 16 Jan 2020 19:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2020-01-16-log/</guid><description>Most Machine Learning projects have seen me write a function to log data to a log-file as well as apply a logarithm to a vector. As I&amp;rsquo;m not aware of a conventionally used synonym for the former use of &amp;rsquo;log&amp;rsquo; and the latter is usually referred to as &amp;rsquo;log&amp;rsquo; in mathematics (thereby rejecting the argument I would usually bring up in naming issues: avoid abbreviations and acronyms) a naming problem naturally arises.</description></item><item><title>2019 in Running</title><link>https://kevinkle.in/posts/2019-12-26-2019_running/</link><pubDate>Fri, 27 Dec 2019 16:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2019-12-26-2019_running/</guid><description>As explained in a previous post, I log the distances of my runs. In the following I will make some simple observations based on this data. The data goes back to 2016 and comprises timestamps and running distances in km.
In bad storytelling manner let&amp;rsquo;s start with the most graspable and interesting statistic first: average and overall distance across years. I had never computed those before and had basically no intuition on it at all.</description></item><item><title>Sort-of-art?</title><link>https://kevinkle.in/posts/2019-09-27-lena/</link><pubDate>Fri, 27 Sep 2019 08:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2019-09-27-lena/</guid><description>Recently, my friend Theo pointed me towards his amazing idea and execution of programming &amp;lsquo;paintings&amp;rsquo; with the help of randomization.
I was fairly taken by the idea of programming with randomization to create sort-of-art. I kept thinking about cellular automata but reckoned that they often created outcomes that looked:
overly structured in general busy, hard and cold in detail. I figured that the latter could maybe be tackled by applying lots of smoothing, both on input and output image.</description></item><item><title>Workflow on Leonhard Compute Cluster</title><link>https://kevinkle.in/posts/2019-02-28-leonhard/</link><pubDate>Thu, 28 Feb 2019 18:00:00 +0200</pubDate><guid>https://kevinkle.in/posts/2019-02-28-leonhard/</guid><description>Abstract Fortunately, ETH provides many of its students with access to Leonhard, a computer cluster with GPUs. Note that only students with certain coursework or projects are granted access. I have spent and lost a fair amount of time due to poor Google results and will describe a setup for a simple workflow.
Connection In order to ssh to the server, you first need to connect to ETH&amp;rsquo;s VPN.
ssh your_nethz@login.</description></item><item><title>Sklearn Pipelines</title><link>https://kevinkle.in/posts/2019-01-10-sklearn-pipelines/</link><pubDate>Tue, 08 Jan 2019 13:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2019-01-10-sklearn-pipelines/</guid><description>Pipeline of transforms with a final estimator.
Why Whether you&amp;rsquo;re using sklearn transformations already or implementing data wrangling from scratch, there are interesting aspects to squeezing those into an sklearn pipeline. Most notably, this will:
Allow for the usage of sklearn&amp;rsquo;s cross validation. Allow for the usage of sklearn&amp;rsquo;s grid search. Lower the barrier to include sklearn transformations, such as TfidfVectorizer, in the future. It would be possible to do all such processing without a pipeline object: once on the whole dataset.</description></item><item><title>Running Log</title><link>https://kevinkle.in/posts/2018-10-21-running-log/</link><pubDate>Sun, 28 Oct 2018 16:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2018-10-21-running-log/</guid><description>Problem Sports tracking apps offer lots of interesting functionalities regarding the logging of activities. I figured most of what they provided was only interesting in short-term for two reasons.
On the one hand, I changed phones and tracking apps from time to time, which would sometimes lead to a reset of information. Also, some tracking apps were discontinued. You could say they introduced technical debt that I often was not willing or able to carry on.</description></item><item><title>Time Is Money</title><link>https://kevinkle.in/posts/2018-07-29-tim/</link><pubDate>Fri, 03 Aug 2018 16:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2018-07-29-tim/</guid><description>This post is about a browser add-on that is hopefully a drop in the ocean towards a rather ambitious goal. It&amp;rsquo;s called TimeIsMoney.
Motivation A while back I listened to Sam Harris&amp;rsquo; podcast with Tristan Harris. What remained was following:
I agreed that most technology is agnostic. At the same time, a lot of technology stemming from or being a byproduct of the attention economy is rather geared towards a usage that is a net disadvantage for the user.</description></item><item><title>Matrix Factorization in Collaborative Filtering</title><link>https://kevinkle.in/posts/2018-07-10-cf-mf/</link><pubDate>Tue, 10 Jul 2018 16:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2018-07-10-cf-mf/</guid><description>The Task We are given a set of tuples representing user-movie ratings, \(\mathcal{R} = \{(i,j,r)\}\), where \(i\) is the user index, \(j\) is the movie index and \(r \in [0, \dots, 5]\) the rating. In the most common scenarios, only a fraction of all user-movie pairs are rated, hence we can talk about sparse data. In other words, most users have only rated a few movies. Now we want to obtain sensible predictions for movies a user has not rated.</description></item></channel></rss>