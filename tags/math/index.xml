<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>math on Blog</title><link>https://kevinkle.in/tags/math/</link><description>Recent content in math on Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 13 Feb 2022 08:00:07 +0200</lastBuildDate><atom:link href="https://kevinkle.in/tags/math/index.xml" rel="self" type="application/rss+xml"/><item><title>Sudoku #3: Poor Man's RL</title><link>https://kevinkle.in/posts/2022-01-09-sudoku_rl/</link><pubDate>Sun, 13 Feb 2022 08:00:07 +0200</pubDate><guid>https://kevinkle.in/posts/2022-01-09-sudoku_rl/</guid><description>Previously, I&amp;rsquo;ve outlined some ideas on how to solve Suduko puzzles. One revolved around depth-first search in trees, one around linear programming. This time I tried my luck with a more adventurous, data-driven approach: Reinforcement Learning. First things first: the approach only works well for 4x4 grids - not for the typical 9x9. Please note that the approached subsequently outlined couldn&amp;rsquo;t be further from a recommendable approach to solving Sudoku puzzles.</description></item><item><title>Sudoku #2: Linear Programming</title><link>https://kevinkle.in/posts/2021-03-14-sudoku_lp/</link><pubDate>Sun, 14 Mar 2021 11:00:07 +0200</pubDate><guid>https://kevinkle.in/posts/2021-03-14-sudoku_lp/</guid><description>Abstract As discussed in this previous post, a given Sudoku puzzle can be modeled in a multitude of ways. Different algorithms ought to still lead to the same solution, since a correct Sudoku puzzle comes with a unique solution. In this post we&amp;rsquo;ll rely on optimization&amp;rsquo;s poster child: Linear programming.
Idea A linear program, subsequently referred to as LP, comes with three central building blocks:
An objective function Typically many variables, each, a priori, non-integer numbers Linear constraints on the variables Since, thanks to our assumption of a well-posed puzzle we know that:</description></item><item><title>Sudoku #1: Depth-First Search</title><link>https://kevinkle.in/posts/2021-02-28-sudoku_dfs/</link><pubDate>Sun, 28 Feb 2021 19:00:07 +0200</pubDate><guid>https://kevinkle.in/posts/2021-02-28-sudoku_dfs/</guid><description>Abstract Solving a Sudoku board can be done in many ways. Let&amp;rsquo;s explore a depth-first search approach in this post.
Idea Depth-first search or DFS implies (at least) two things:
a graph, or rather, a tree a search This bares the question: What&amp;rsquo;s the tree and what are we searching for?
The tree A tree must consist of nodes and edges. We define the nodes to represent a &amp;lsquo;state&amp;rsquo; of the game.</description></item><item><title>Markov Random Field Image Denoising</title><link>https://kevinkle.in/posts/2020-03-27-mrf/</link><pubDate>Sun, 26 Apr 2020 09:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2020-03-27-mrf/</guid><description>This post describes the application of a Probabilistic Graphical Model for simple image denoising, as suggested in Bishop&amp;rsquo;s chapter 8.3.8. I will attempt to introduce some notions for general context without derivations. Googling will lead to plenty of useful resources. On an introductory level, I enjoyed Daphne Koller&amp;rsquo;s class.
Context: Probabilistic Graphical Models Probabilistic Graphical Models are tools to model and express conditional independencies among a set of random variables.</description></item><item><title>Invitations</title><link>https://kevinkle.in/posts/2020-03-02-invitations/</link><pubDate>Mon, 02 Mar 2020 09:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2020-03-02-invitations/</guid><description>Scenario and goal You are the host of an event for which there are \(n\) candidates to be invited and you possess sufficient resources to host all candidates. Let the nature of the event be such that it seems personally attached to you, yet also fairly polarizing in its experience. In other words:
some invitees will have a desire to decline invitees with a desire to decline will feel bad about declining some non-invitees will have a desire to attend non-invitees with a desire to attend will feel bad about not being able to attend Moreover, one might weigh the ambitions wrt non-desiring invitees and desiring non-invitees differently.</description></item><item><title>Sort-of-art?</title><link>https://kevinkle.in/posts/2019-09-27-lena/</link><pubDate>Fri, 27 Sep 2019 08:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2019-09-27-lena/</guid><description>Recently, my friend Theo pointed me towards his amazing idea and execution of programming &amp;lsquo;paintings&amp;rsquo; with the help of randomization.
I was fairly taken by the idea of programming with randomization to create sort-of-art. I kept thinking about cellular automata but reckoned that they often created outcomes that looked:
overly structured in general busy, hard and cold in detail. I figured that the latter could maybe be tackled by applying lots of smoothing, both on input and output image.</description></item><item><title>Breaking Pills: An Intuition</title><link>https://kevinkle.in/posts/2019-09-23-breaking_pills/</link><pubDate>Mon, 23 Sep 2019 09:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2019-09-23-breaking_pills/</guid><description>Motivation Recently, Mark Dominus&amp;rsquo; post on breaking pills appeared on Hacker News. I was surprised to see the author not provide a closed-form and wanted to extend on some of the comments indicating a relation to the harmonic numbers.
Problem Formulation Starting off with a bowl of \(n\) whole pills, you draw from the bowl uniformly at random according to the following mechanism: if the drawn pill is whole, you put back one half of it; if the drawn pill is half, you don&amp;rsquo;t put back anything.</description></item><item><title>A Beautiful, Derandomized Algorithm</title><link>https://kevinkle.in/posts/2019-01-22-favourite-algorithm/</link><pubDate>Mon, 21 Jan 2019 16:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2019-01-22-favourite-algorithm/</guid><description>Abstract Appreciating the simplicity of powerful randomized algorithms comes easy to me. In the following I will try to describe a naive algorithm relying on a randomized argument. What I find particularly remarkable is that it can easily parry the critique I am so often encountered with when cherishing randomized algorithms: it can trivially be turned deterministic.
MAX-3SAT Is a boolean satisfiability problem. Given a formula in 3-CNF, the goal to satisfy as many clauses as possible.</description></item><item><title>Matrix Factorization in Collaborative Filtering</title><link>https://kevinkle.in/posts/2018-07-10-cf-mf/</link><pubDate>Tue, 10 Jul 2018 16:38:07 +0200</pubDate><guid>https://kevinkle.in/posts/2018-07-10-cf-mf/</guid><description>The Task We are given a set of tuples representing user-movie ratings, \(\mathcal{R} = \{(i,j,r)\}\), where \(i\) is the user index, \(j\) is the movie index and \(r \in [0, \dots, 5]\) the rating. In the most common scenarios, only a fraction of all user-movie pairs are rated, hence we can talk about sparse data. In other words, most users have only rated a few movies. Now we want to obtain sensible predictions for movies a user has not rated.</description></item></channel></rss>