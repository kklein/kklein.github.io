---
layout: post
title:  "Matrix Factorization in Collaborative Filtering"
date:   2018-07-10 16:38:07 +0200
categories: jekyll update
---
<script type="text/javascript" async
src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?
config=TeX-AMS-MML_HTMLorMML"></script>


## The Task
<!--#### The Task, for real-->
We are given a set of tuples representing user-movie ratings, \\(\\mathcal{R} = \\{(i,j,r)\\}\\), where \\(i\\) is the user index, \\(j\\) is the movie index and \\(r \in [0, \\dots, 5]\\) the rating.
In the most common scenarios, only a fraction of all user-movie pairs are rated, hence we can talk about _sparse_ data.
In other words, most users have only rated a few movies. Now we want to obtain sensible predictions for movies a user has not rated. I leave drawing to picture as to why this is super relevant in many use cases to your imagination.

#### Why plain 'looking at similar users' won't work
In order to predict \\(\\hat{r_{ij}}\\), one might come up with the idea of looking for a user \\(i'\\) with a rating history that was _close_ or _similar_ to that of user \\(i\\) and see how those users rated movie \\(j\\). One often refers to this as 'Neighborhood' methods.
As of now, this approach has its limitation due to the _sparseness_ of the data. As most users have only rated 'few' movies, it might be that the users who actually have _similar_ preferences to \\(i\\) have rated completely different movies than \\(i\\) and therefore will not be detected.
In short, the high dimensionality (#movies) and sparseness of the data makes this approach fairly unfavorable. We will overcome this issue by using a lower-dimensional representation, aka _embedding_, of the data.

## Low-hanging fruit: SVD
Given a matrix \\(M\\), the Singular Value Decomposition gives us a factorization of it: \\(M = U \\Sigma D^T\\). As we are rather looking for a factorization with only two instead of three terms it comes in very handy that \\(\\Sigma\\) is both diagonal and positive. Hence we can write \\(M = PQ^T\\) with \\(P := U \\sqrt{\\Sigma}, Q := D \\sqrt{\\Sigma}\\). Informally, given that \\(M\\) holds \\(movies \\times users\\), \\(P\\) will then hold \\(movies \\times topics\\) and \\(Q\\) \\(users \\times topics\\). These topics are implicitly chosen by SVD and also referred to as hidden/latent factors, concepts, features or dimensions of the embedding.

#### Why can we use SVD?

In order to apply SVD, we need \\(M\\) to come from somewhere.
We create \\(M\\) based on user the given user ratings. For each \\((i,j,r) \in \\mathcal{R}\\) we set \\(M[i,j] = r\\). Now this makes for a 'matrix' _full of holes_, as most index tuples of the matrix will not be a rating. So not a real matrix. We fix this by _imputing_ \\(M\\), i.e. we fill the holes by a heuristic and call this new, actually legitimate matrix \\(M'\\). Filling a hole \\((i,j)\\) by the average of row \\(i\\), i.e. the average rating given by user \\(i\\), typically works somewhat decently. As you can imagine, there are far more elaborate heuristics for this. Yet it remains an imputation, we don't just get more signal for free.

#### Why do we use SVD?

What's most valuable to us with regard to SVD is that it ranks the features by their importance (insert ref) for reconstruction of the initial data. Now the crucial thing is that we make the assumption that the data is actually generated from a distribution on a low-dimensional space to which a lot of noise is added, which is then manifested in a high-dimensional space. Now this high-dimensional space is \\(\\{0,1,2,3,4,5, unrated\\}^{\\#movies}\\). What we hope is that eliminating all but the most important hidden factors from SVD will give us this underlying representation and eliminate all the noise. Then from low dimensional representation, i.e. embedding, we map back to the space we originally came from and have more accurate rating estimations, with hopefully less noise. Interestingly, given an embedding-dimensionality \\(k\\), we know that SVD will given us [optimal properties](https://en.wikipedia.org/wiki/Low-rank_approximation#Proof_of_Eckart%E2%80%93Young%E2%80%93Mirsky_theorem_(for_spectral_norm)) on a certain loss function.

#### How do we use SVD?

Instead of factorizing \\(M'\\) with \\(PQ^T\\), we now _approximate_ it. We can do that by dropping all but \\(k\\) of the columns (from the right as they are ordered by 'importance') of \\(P\\) and \\(Q\\) and calling those matrices \\(P'\\) and \\(Q'\\), with fewer hidden factors. We obtain: \\(M' \\approx P_kQ_k^T\\). \\(k\\) is typically chosen by trial and error as well as thresholding on the importance values. For the sake of concreteness, think of the following orders of magnitude:

| \\(\\#users\\)        | \\(\\#movies\\)           | \\(k\\)  |
| :-------------: |:-------------:| :-----:|
| \\(10^6\\)     | \\(10^5\\) | \\(10^1\\) |

Given such a \\(k\\) and the matrix \\(M'\\), SVD will minimize the following loss function for \\(P_k\\) and \\(Q_k\\):
\\[ \\mathcal{L} = ||M' - P_kQ_k^T||\_N\\]
where \\(N\\) indicates either [2](http://mathworld.wolfram.com/SpectralNorm.html) or [Frobenius norm](http://mathworld.wolfram.com/FrobeniusNorm.html).

#### [Is this it? Said they'd give you anything you ever wanted.](https://youtu.be/8nQowpGZsG4)

Yes. We obtain a hopefully denoised and enhanced estimate of rating \\(r_{ij}\\) by the following steps:
1. SVD embeds both users and movies in lots of hidden factors. We get the user embedding \\(p_i \\in R^{\\#movies}\\) and movie embedding \\(q_j \in R^{\\#users}\\).
2. We cut \\(p_i\\) to only use its first \\(k\\) elements.
3. We cut \\(q_j\\) to only use its first \\(k\\) elements.
4. We use the dot-product as a similarity measure. Given that both the user and movie are now represented in the same space of hidden factors, our rating is just \\(p_i^Tq_j\\).

Hence, the overall predictions will be contained in \\(P_kQ_k^T\\).

#### Conclusion
SVD beautifully leverages fairly simple Linear Algebra to produce somewhat decent predictions. Given its simplicity, this method works great. Nevertheless there are two substantial shortcomings that come to my mind:

<a name="p1"></a>Problem1 | SVD succesfully minimizes a loss function. Yet said loss function weights the imputed values just as much as the actual ratings. This sounds terrible to me.

<a name="p3"></a>Problem2 | We might want to have explicit biases for users and movies, involved in the estimation of each rating.

<a name="p3"></a>Problem3 | No regularization, which could lead to overfitting on a few very dominant dimensions.

Those pain points give rise to defining a new [loss function](#new).

#### Addendum: Iterated SVD
The chosen method of imputation is very impactful, as most values will be imputed. Lovely [Jonas Felber](http://felberj.ch/) recommended to reduce the importance of initial imputation and improve estimate quality by the following process:
```python
M # imputed data matrix
k # chosen dimensionality
for i in range(n_epochs):
  U, S, D = svd(M) # SVD composition, factors ordered according to importance
  P = U * sqrt(S) # User embeddings
  Q = D * sqrt(S) # Movie embeddings
  M = P[:, :k] * Q[:, :k].transpose
  fill_initial_user_ratings_back_into_matrix(M)
return M
```
Essentially, now we're using the predictions from a previous iteration as a way of imputing the data, over and over again. My understanding is that the reinsertion of the given ratings reduces the importance of the initial, manual imputation. This approach increased the quality of estimates drastically, in my case.
## Not so low hanging fruit
We first define a different loss function and then think of how to minimize it.
#### <a name="new"></a>Towards a more appropriate loss function

Addressing the [issues](#p1) encountered with SVD, we will no longer be able to guarantee an optimal solution, largely due to the problem not being convex. Still, a local optimum incorporating fixes to those issues is promising to be enhancement over SVD. In a way, I think of sacrificing _efficiency for effectiveness_.

1. Problem 1:
Instead of iterating over all indices, including those of imputed values, we just look at the given ratings.
\\[ \\mathcal{L} = \\sum_{(i,j,r) \\in R} (r - \\hat{r_{ij}})^2\\]

2. Problem 2:
We can simply add bias terms per user and movie, such that our estimate looks like this:
\\[\\hat{r_{ij}} = p_i^T q_j + bu_i + bm_j \\]

3. Problem 3:
As we are trying to learn both embeddings and biases of users and movies, all of those should be regularized.
\\[D = \\lambda(||U||\_F^2 + ||Q||\_F^2 + ||bu||\_2^2 + ||bm||\_2^2)\\]

Hence our overall loss function is \\(\\mathcal{L}_D = \\mathcal{L} + D\\)

#### Stochastic Gradient Descent
Despite the loss function, as well as e.g. \\(\\frac{\\partial L_D}{\\partial p_i}\\), iterating over all given ratings, we aim to avoid iterations over the whole dataset per update/iteration. Our compromise is to only look at one randomly chosen rating \\((i,j,r)\\) at a time and investigate the loss function:
\\[ (r - \\hat{r_{ij}})^2 + \\lambda(||p_i||\_2^2 + ||q_j||\_2^2 + ||bu_i||\_2^2 + ||bm_j||\_2^2)\\]
Therefore our overall process is to shuffle the training set, iterate over individual datapoints and update embeddings and biases impacted by that datapoint. We repeat this process until 'convergence' is reached.
Note that this approach still requires initialization of \\(P\\) and \\(Q\\) to begin with. I think a fairly conventional approach is to initialize them with random numbers from \\([0,1]\\). For my purposes, it has worked well to initialize them via aforementioned SVD.

#### Updates
Note that the loss function is not convex in the tuple \\((P, Q)\\), hence it is not straightforward how to define \\(P, Q, bu, bm\\) minimizing it jointly. I came across three approaches.
1. Alternating optimization
This approach revolves around the fact that \\(\mathcal{L_D}\\) is convex in \\(P\\) for a _fixed_ \\(Q\\) and vice versa. So this approach initializes both embedding matrices in some way and then takes turns updating either movie or user embedding based on their relative gradient of the loss function.
This approach didn't work great for me.

2. Simultaneous updates with Stochastic Gradient Descent
In this approach we basically just update everything at the same time and hope for the best.

3. Coordinate Descent
Per datapoint \\((i,j,r)\\), instead of updating \\(p_i, q_j\\), we update only one dimension of the embedding vectors at a time. In particular we only update the \\(l\\)-th dimension until we have reached 'convergence'. We then continue by fixing dimension \\(l\\) and start the same procedure for dimension \\(l+1\\). To my knowledge, this appraoch was popularized by [Simon Funk](http://sifter.org/simon/journal/20061211.html),



# TODOS
- References
- Further reading
- Clarifying ALS
- Clarifying SGD
